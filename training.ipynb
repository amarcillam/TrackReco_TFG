{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06b9696",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.gnn_model import gnn\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import copy as copy\n",
    "import time as time\n",
    "import statistics\n",
    "from scripts import utils\n",
    "import random\n",
    "from sklearn.metrics import (f1_score, average_precision_score, recall_score, roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae028e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunked_list(lst, chunk_size):\n",
    "\n",
    "    '''Se encarga de seleccionar los nombres de los chunks de \n",
    "    grafos que serán cargados en RAM desde el disco para evitar \n",
    "    saturación'''\n",
    "\n",
    "    for i in range(0, len(lst), chunk_size):\n",
    "        yield lst[i:i + chunk_size]\n",
    "\n",
    "class FocalLoss(torch.nn.Module):\n",
    "\n",
    "    '''Función de pérdida, el parámetro solo_BCE activa y desactiva\n",
    "    la focalización en la clase minoritaria necesaria para\n",
    "    distribuciones desbalanceadas'''\n",
    "\n",
    "    def __init__(self, alpha=0.25, gamma=2, solo_BCE=True):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.solo_BCE = solo_BCE\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        BCE_loss = torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "            logits, targets, reduction='none')\n",
    "        probs = torch.sigmoid(logits)\n",
    "        pt = torch.where(targets == 1, probs, 1 - probs)\n",
    "        focal_weight = self.alpha * (1 - pt) ** self.gamma\n",
    "        if self.solo_BCE:\n",
    "            out = BCE_loss.mean() \n",
    "        else:\n",
    "            out = (focal_weight * BCE_loss).mean()\n",
    "        return out\n",
    "\n",
    "def train(model, train_dir, test_dir, config_number, epochs, lr, solo_BCE, chunk_size=50):\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-5, cooldown=3)\n",
    "\n",
    "    train_files = {}\n",
    "    for fname in os.listdir(train_dir): #si los eventos estan divididos en subgrafos se agrupan losd e un mismo evento\n",
    "        if not fname.endswith('.pt'): continue\n",
    "        ev = fname.split('_')[0]\n",
    "        train_files.setdefault(ev, []).append(os.path.join(train_dir, fname))\n",
    "    for ev in train_files:\n",
    "        train_files[ev].sort()\n",
    "    train_events = sorted(train_files.keys())\n",
    "\n",
    "    test_batches = [] #los grafos de validación siempre en memoria\n",
    "    for fname in os.listdir(test_dir):\n",
    "        if not fname.endswith('.pt'): continue\n",
    "        g = torch.load(os.path.join(test_dir, fname), weights_only=False)\n",
    "        for attr in ['hit_id', 'particle_id']:\n",
    "            if hasattr(g, attr): delattr(g, attr)\n",
    "        test_batches.append(g)\n",
    "\n",
    "    all_pw = []\n",
    "    for ev in train_events: #estimación de parámetros de focalización\n",
    "        for chunk in chunked_list(train_files[ev], chunk_size):\n",
    "            for path in chunk:\n",
    "                g = torch.load(path, weights_only=False)\n",
    "                y = g.y\n",
    "                pos = int(y.sum().item())\n",
    "                neg = int(y.numel() - pos)\n",
    "                if pos > 0:\n",
    "                    all_pw.append(neg/pos)\n",
    "            del g\n",
    "            torch.cuda.empty_cache()\n",
    "            break\n",
    "    mean_pw = statistics.mean(all_pw) if all_pw else 1.0\n",
    "    alpha = mean_pw / (mean_pw + 1)\n",
    "    print(f\"Alpha para FocalLoss = {alpha:.4f}\")\n",
    "    loss_fn = FocalLoss(alpha=alpha, gamma=2, solo_BCE=solo_BCE)\n",
    "\n",
    "    train_losses, train_accs = [], []\n",
    "    test_losses,  test_accs  = [], []\n",
    "    epoch_f1s, epoch_pr_aucs = [], []\n",
    "    epoch_rec_pos, epoch_rec_neg = [], []\n",
    "    epoch_roc_aucs = []\n",
    "\n",
    "    y_true_final = y_probs_final = y_pred_final = None #par aultima validación\n",
    "\n",
    "    # TRAIN ==================================\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        tot_corr = tot_edges = 0\n",
    "\n",
    "        perm = train_events.copy()\n",
    "        random.seed(epoch)\n",
    "        random.shuffle(perm)\n",
    "\n",
    "        for ev in perm:\n",
    "            for chunk in chunked_list(train_files[ev], chunk_size):\n",
    "                graphs = [torch.load(p, weights_only=False).to(device) for p in chunk]\n",
    "                for g in graphs:\n",
    "                    for attr in ['hit_id', 'particle_id']:\n",
    "                        if hasattr(g, attr): delattr(g, attr)\n",
    "                    y = g.y.float().to(device)\n",
    "                    logits = model(g).view(-1)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss = loss_fn(logits, y)\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                    optimizer.step()\n",
    "                    preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "                    tot_corr += (preds == y).sum().item()\n",
    "                    tot_edges += y.numel()\n",
    "                del graphs\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        train_loss = loss.item()\n",
    "        train_acc  = tot_corr / tot_edges\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "\n",
    "        # TEST ==================================\n",
    "        model.eval()\n",
    "        test_corr = test_tot = 0\n",
    "        all_labels, all_probs = [], []\n",
    "        with torch.no_grad():\n",
    "            for g in test_batches:\n",
    "                g = g.to(device)\n",
    "                y = g.y.float().to(device)\n",
    "                logits = model(g).view(-1)\n",
    "                _ = loss_fn(logits, y).item()\n",
    "                prob = torch.sigmoid(logits)\n",
    "                test_corr += (prob.round() == y).sum().item()\n",
    "                test_tot  += y.numel()\n",
    "                all_labels.append(y.cpu())\n",
    "                all_probs.append(prob.cpu())\n",
    "\n",
    "        test_loss = sum(\n",
    "            loss_fn(model(g.to(device)).view(-1), g.y.float().to(device)).item()\n",
    "            for g in test_batches\n",
    "        ) / len(test_batches)\n",
    "        test_acc = test_corr / test_tot\n",
    "        test_losses.append(test_loss)\n",
    "        test_accs.append(test_acc)\n",
    "\n",
    "        #para metricas\n",
    "        y_t = torch.cat(all_labels).numpy()\n",
    "        y_p = torch.cat(all_probs).numpy()\n",
    "        y_h = (y_p > 0.5).astype(int)\n",
    "\n",
    "        epoch_f1s.append(f1_score(y_t, y_h))\n",
    "        epoch_pr_aucs.append(average_precision_score(y_t, y_p))\n",
    "        epoch_rec_pos.append(recall_score(y_t, y_h, pos_label=1))\n",
    "        epoch_rec_neg.append(recall_score(y_t, y_h, pos_label=0))\n",
    "        fpr, tpr, _ = roc_curve(y_t, y_p)\n",
    "        epoch_roc_aucs.append(auc(fpr, tpr))\n",
    "\n",
    "        #para el plot final\n",
    "        y_true_final = y_t\n",
    "        y_probs_final = y_p\n",
    "        y_pred_final = y_h\n",
    "\n",
    "        print(\n",
    "            f\"\\rEpoch {epoch:3d} | \"\n",
    "            f\"Train L: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
    "            f\"Test  L: {test_loss:.4f} Acc: {test_acc:.4f} | \"\n",
    "            f\"F1: {epoch_f1s[-1]:.4f} PR–AUC: {epoch_pr_aucs[-1]:.4f} ROC–AUC: {epoch_roc_aucs[-1]:.4f}\",\n",
    "            end=\"\", flush=True\n",
    "        )\n",
    "        scheduler.step(test_loss)\n",
    "\n",
    " \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    #Loss\n",
    "    axes[0,0].plot(train_losses, label=\"Train Loss\")\n",
    "    axes[0,0].plot(test_losses,  label=\"Test Loss\")\n",
    "    axes[0,0].set_title(\"Loss por Época\")\n",
    "    axes[0,0].set_xlabel(\"Época\"); axes[0,0].set_ylabel(\"Loss\")\n",
    "    axes[0,0].legend(); axes[0,0].grid(True)\n",
    "\n",
    "    #accuracy\n",
    "    axes[0,1].plot(train_accs, label=\"Train Acc\")\n",
    "    axes[0,1].plot(test_accs,  label=\"Test Acc\")\n",
    "    axes[0,1].set_title(\"Accuracy por Época\")\n",
    "    axes[0,1].set_xlabel(\"Época\"); axes[0,1].set_ylabel(\"Accuracy\")\n",
    "    axes[0,1].legend(); axes[0,1].grid(True)\n",
    "    \n",
    "    #métricas\n",
    "    epochs_range = list(range(1, epochs+1))\n",
    "    axes[0,2].plot(epochs_range, epoch_pr_aucs,  label=\"PR–AUC\")\n",
    "    axes[0,2].plot(epochs_range, epoch_f1s,      label=\"F1\")\n",
    "    axes[0,2].plot(epochs_range, epoch_rec_pos,  label=\"Recall Positiva\")\n",
    "    axes[0,2].plot(epochs_range, epoch_rec_neg,  label=\"Recall Negativa\")\n",
    "    axes[0,2].plot(epochs_range, epoch_roc_aucs, label=\"ROC–AUC\")\n",
    "    axes[0,2].set_title(\"Métricas por Época\")\n",
    "    axes[0,2].set_xlabel(\"Época\"); axes[0,2].set_ylabel(\"Valor\")\n",
    "    axes[0,2].set_ylim(0,1.1); axes[0,2].legend(loc=\"lower right\", ncol=2)\n",
    "    axes[0,2].grid(True)\n",
    "\n",
    "    #matriz de confusión\n",
    "    cm = confusion_matrix(y_true_final, y_pred_final)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Neg\",\"Pos\"])\n",
    "    disp.plot(ax=axes[1,0], cmap=plt.cm.Blues, colorbar=False)\n",
    "    axes[1,0].set_title(\"Matriz de Confusión (Test)\")\n",
    "\n",
    "    #roc\n",
    "    fpr_f, tpr_f, _ = roc_curve(y_true_final, y_probs_final)\n",
    "    roc_auc_f = auc(fpr_f, tpr_f)\n",
    "    axes[1,1].plot(fpr_f, tpr_f, label=f\"AUC = {roc_auc_f:.4f}\")\n",
    "    axes[1,1].plot([0,1],[0,1],\"k--\", label=\"Aleatorio\")\n",
    "    axes[1,1].set_title(\"Curva ROC (Test)\")\n",
    "    axes[1,1].set_xlabel(\"FPR\"); axes[1,1].set_ylabel(\"TPR\")\n",
    "    axes[1,1].set_xlim(0,1); axes[1,1].set_ylim(0,1)\n",
    "    axes[1,1].legend(loc=\"lower right\"); axes[1,1].grid(True)\n",
    "    \n",
    "    axes[1,2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    final_f1 = epoch_f1s[-1]\n",
    "\n",
    "    if solo_BCE:\n",
    "        fig_path = f\"models/plot_model_f1_{final_f1:.7f}.png\"\n",
    "        model_path = f\"models/model_f1_{final_f1:.7f}_config_{config_number}.pt\"\n",
    "    else:\n",
    "        fig_path = f\"models/plot_model_f1_{final_f1:.7f}_pt_filter.png\"\n",
    "        model_path = f\"models/model_f1_{final_f1:.7f}_config_{config_number}_pt_filter.pt\"\n",
    "\n",
    "    fig.savefig(fig_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Gráfica guardada en: {fig_path}\")\n",
    "    print(f\"Modelo guardado en: {model_path}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74372546",
   "metadata": {},
   "source": [
    "# Train con filtro ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb2487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_number = 2\n",
    "model_hyper, preprocess_hyper = utils.load_hyper(name = f'config{config_number}')\n",
    "\n",
    "model = gnn(**model_hyper)\n",
    "\n",
    "trained = train(\n",
    "    model,\n",
    "    train_dir      = 'data/dataset_graphs_ideal/train',\n",
    "    test_dir       = 'data/dataset_graphs_ideal/test',\n",
    "    config_number  = 2,\n",
    "    epochs         = 300,\n",
    "    lr             = 1e-3,\n",
    "    solo_BCE = True,\n",
    "    chunk_size     = 50) # eventos cargados de cada vez\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5759c80c",
   "metadata": {},
   "source": [
    "# Train con filtro real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1315717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ejecutar esta celda solo si la celda anterior no ha sido ejecutada\n",
    "config_number = 2\n",
    "model_hyper, preprocess_hyper = utils.load_hyper(name = f'config{config_number}')\n",
    "\n",
    "model = gnn(**model_hyper)\n",
    "\n",
    "trained = train(\n",
    "    model,\n",
    "    train_dir      = 'data/dataset_graphs_real/train',\n",
    "    test_dir       = 'data/dataset_graphs_real/test',\n",
    "    config_number  = config_number,\n",
    "    epochs         = 150,\n",
    "    lr             = 1e-3,\n",
    "    solo_BCE = False,\n",
    "    chunk_size     = 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
